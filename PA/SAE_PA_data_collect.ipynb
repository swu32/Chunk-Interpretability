{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc8eee-86a3-475c-84bd-711c1faaa677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"Your API key\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = torch.device(\"cuda:2\")  # or \"cpu\"\n",
    "from sparsify import Sae\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from util import *\n",
    "\n",
    "model_name = 'llama3'\n",
    "trainkey = 'prompt_with_cheesecake_train'\n",
    "key = trainkey\n",
    "word = \"cheese\"\n",
    "step = 0\n",
    "partword = True \n",
    "\n",
    "with open('./data_collection/prompt_bank.json', 'r') as file:\n",
    "    prompt_bank = json.load(file)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "input_text_train = prompt_bank[trainkey]\n",
    "input_text_test = prompt_bank[testkey]\n",
    "\n",
    "\n",
    "trainkey = 'prompt_with_cheesecake_train'\n",
    "testkey = 'prompt_with_cheesecake_test'\n",
    "for word in ['cheese','cake','cheesecake']:\n",
    "    tokenstrain = obtain_sentence_wise_token(tokenizer, input_text_train,device)\n",
    "    indicestrain = get_word_indices_in_sequence_partword(tokenstrain, word, step = step) # n step predictive of the upcoming sequence\n",
    "\n",
    "    tokenstest = obtain_sentence_wise_token(tokenizer, input_text_test, device)\n",
    "    indicestest = get_word_indices_in_sequence_partword(tokenstest, word, step = step) # n step predictive of the upcoming sequence\n",
    "    \n",
    "    maximal_neural_activities_train=[]\n",
    "    maximal_neural_activities_test=[]\n",
    "\n",
    "    for i in range(1,32): # iterate through layer, no layer 31, and 32, from EleutherAI tho\n",
    "        concatenated_hidden_state = np.load(f'./hidden_unit_activity/{trainkey}_concatenated_hidden_state_layer_{i}_model={model_name}.npy')\n",
    "        hidden_state = concatenated_hidden_state[0,:,:]\n",
    "        hidden_state = torch.from_numpy(hidden_state).float().to(device)\n",
    "        sae = Sae.load_from_hub(\"EleutherAI/sae-llama-3-8b-32x\", hookpoint=f\"layers.{i-1}\").to(device)\n",
    "        encoder_output = sae.encode(hidden_state)\n",
    "        #### extract the maximally activating SAE neurons \n",
    "        max_neuron_index, max_avg_value = find_maximal_neuron(indicestrain, encoder_output)\n",
    "        neural_activity = get_batched_neural_activity(max_neuron_index, encoder_output)\n",
    "        maximal_neural_activities_train.append(neural_activity)\n",
    "\n",
    "        # load_test, record the activity of the neuron found with maximal activity in the training data \n",
    "        concatenated_hidden_state = np.load(f'./hidden_unit_activity/{testkey}_concatenated_hidden_state_layer_{i}_model={model_name}.npy')\n",
    "        hidden_state = concatenated_hidden_state[0,:,:]\n",
    "        hidden_state = torch.from_numpy(hidden_state).float().to(device)\n",
    "        encoder_output = sae.encode(hidden_state)\n",
    "        neural_activity = get_batched_neural_activity(max_neuron_index, encoder_output)\n",
    "        maximal_neural_activities_test.append(neural_activity)\n",
    "        del sae\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    combined_train = np.stack(maximal_neural_activities_train,axis=0)\n",
    "    combined_test = np.stack(maximal_neural_activities_test,axis=0)\n",
    "\n",
    "    # np.save(f\"/shared-network/swu/code/experiment_data/sae_key={trainkey}_word={word}.npy\", combined_train)\n",
    "    # np.save(f\"/shared-network/swu/code/experiment_data/sae_key={testkey}_word={word}.npy\", combined_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fddf6-3a52-43c4-ad1e-f0b10a5485a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"Your API TOKEN\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = torch.device(\"cuda:2\")  # or \"cpu\"\n",
    "from sparsify import Sae\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from util import *\n",
    "\n",
    "model_name = 'sae'\n",
    "step = 0\n",
    "partword = True \n",
    "\n",
    "trainkey = 'prompt_with_cheesecake_train'\n",
    "testkey = 'prompt_with_cheesecake_test'\n",
    "with open('./data_collection/prompt_bank.json', 'r') as file:\n",
    "    prompt_bank = json.load(file)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "input_text = prompt_bank[trainkey]\n",
    "\n",
    "experiment_data = []\n",
    "neural_chunk_dictionary = {}\n",
    "for word in ['cheese','cake','cheesecake']:\n",
    "    neural_chunk_dictionary[word] = {}\n",
    "    neural_chunk_dictionary[word][step] = {}\n",
    "    neural_chunk_dictionary[word][step]['layer'] = {}\n",
    "    for layer in range(0,32):\n",
    "        neural_chunk_dictionary[word][step]['layer'][layer] = {}\n",
    "        neural_chunk_dictionary[word][step]['layer'][layer]['dev_threshold'] = {}\n",
    "\n",
    "for word in ['cheese','cake','cheesecake']:\n",
    "    input_text = prompt_bank[trainkey]\n",
    "\n",
    "    if trainkey == 'austen-emma.txt':tokens = get_token_austin(tokenizer, input_text,device)\n",
    "    else:tokens = obtain_sentence_wise_token(tokenizer, input_text,device)\n",
    "    indices = get_word_indices_in_sequence(tokens, word, step = step) # n step predictive of the upcoming sequence\n",
    "    if partword: indices = get_word_indices_in_sequence_partword(tokens, word, step = step) # n step predictive of the upcoming sequence\n",
    "    combined = np.load(f\"./sae_key={trainkey}_word={word}.npy\")\n",
    "\n",
    "    layers, best_accs, best_tps, best_fps = [], [], [], []\n",
    "    for layer in range(0,combined.shape[0]):\n",
    "        hidden_activity = combined[layer, :]\n",
    "        n_training = len(indices)\n",
    "        T_range = np.unique(hidden_activity)\n",
    "        T_range.sort()  # sorts in-place from smallest to largest\n",
    "        max_acc = 0\n",
    "        max_tp = 0\n",
    "        accs, tps, fps = [], [], []\n",
    "        for dev in T_range: \n",
    "            TP_rate, FP_rate, accuracy,_ = get_TP_FP_sae(hidden_activity, indices, tokens, dev)\n",
    "            # print(TP_rate, FP_rate, dev, accuracy)\n",
    "            if accuracy>max_acc:\n",
    "                max_acc = accuracy\n",
    "                best_threshold = dev \n",
    "                neural_chunk_dictionary[word][step]['layer'][layer]['dev_threshold'] = dev\n",
    "            for lst, value in zip([accs, tps, fps], [accuracy, TP_rate, FP_rate]):\n",
    "                lst.append(value)\n",
    "            if TP_rate > max_tp:max_tp = TP_rate\n",
    "        #print('------------------')\n",
    "        TP_rate, FP_rate, accuracy,_ = get_TP_FP_sae(hidden_activity, indices, tokens, best_threshold)\n",
    "        # print('------------------')\n",
    "    \n",
    "        temp = []\n",
    "        for i in range(0, len(tps)):\n",
    "            if tps[i]>=max_tp:temp.append(fps[i])\n",
    "        fps_sorted, tps_sorted = zip(*sorted(zip(fps, tps)))\n",
    "        fps_sorted = fps_sorted + (1,)\n",
    "        tps_sorted = tps_sorted + (1,)\n",
    "        auc = np.trapezoid(tps_sorted, fps_sorted)\n",
    "        \n",
    "        layers.append(layer)\n",
    "        best_accs.append(accuracy)\n",
    "        best_tps.append(TP_rate)\n",
    "        best_fps.append(FP_rate)\n",
    "        print(TP_rate, best_tps)\n",
    "        experiment_data.append({'Model': model_name, 'Word': word ,'step': step, 'TP': TP_rate, 'FP': FP_rate,'n_training': n_training, 'Layer': layer, 'Training': True, 'Test': False})\n",
    "    plot_decoding_performance(layers, best_tps, best_fps, step = step, word = word, testdata = False,model_name = model_name)\n",
    "    \n",
    "    # with open(f\"./neural_chunk_dictionary/neural_chunk_dictionary_sae.pkl\", \"wb\") as file:\n",
    "    #     pickle.dump(neural_chunk_dictionary, file)\n",
    "    ############### test performance evaluation ##############\n",
    "    input_text = prompt_bank[testkey]\n",
    "    if testkey == 'austen-persuasion.txt':tokens = get_token_austin(tokenizer, input_text,device)\n",
    "    else:tokens = obtain_sentence_wise_token(tokenizer, input_text,device)\n",
    "\n",
    "    indices = get_word_indices_in_sequence(tokens, word, step = step)\n",
    "    if partword: indices = get_word_indices_in_sequence_partword(tokens, word, step = step) # n step predictive of the upcoming sequence\n",
    "\n",
    "    combined = np.load(f\"./sae_key={testkey}_word={word}.npy\")\n",
    "    assert word in neural_chunk_dictionary \n",
    "    layers, accs, tps, fps = [], [], [], []\n",
    "    for layer in range(0,combined.shape[0]): # \n",
    "        hidden_activity = combined[layer, :] # Load the hidden state from the saved file\n",
    "        best_threshold = neural_chunk_dictionary[word][step]['layer'][layer]['dev_threshold']\n",
    "        TP_rate, FP_rate, accuracy,_ = get_TP_FP_sae(hidden_activity,indices,tokens, best_threshold)\n",
    "        print(TP_rate, FP_rate, accuracy)\n",
    "        experiment_data.append({'Model': model_name, 'Word': word ,'step': step, 'TP': TP_rate, 'FP': FP_rate,'n_training': n_training, 'Layer': layer, 'Training': False, 'Test': True})\n",
    "        for lst, value in zip([accs, tps, fps, layers], [accuracy, TP_rate, FP_rate, layer]):\n",
    "            lst.append(value)\n",
    "\n",
    "        layers.append(layer)\n",
    "        accs.append(accuracy)\n",
    "        tps.append(TP_rate)\n",
    "        fps.append(FP_rate)\n",
    "    \n",
    "    plot_decoding_performance(layers, tps, fps, word = word, step = step, testdata = True, model_name = model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee5afdc1-e99e-4f79-8f4c-b0f6acd9695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxsaedata = np.load(\"./sae_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94bc194-bf4a-4624-8f54-3378836f025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take the activity of the maximally activity neuron when cheese is present across the batch, \n",
    "# and we use the activity of this neuron to determine the prescence of cheese "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35d0dc12-4cda-4646-9a35-4f4b4f541e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(0,combined.shape[0]):\n",
    "    hidden_activity = combined[layer, :]\n",
    "    T_range = np.unique(hidden_activity)\n",
    "    T_range.sort()  # sorts in-place from smallest to largest\n",
    "    # choose the best deviation threshold \n",
    "    max_acc = 0\n",
    "    max_tp = 0\n",
    "    layers, accs, tps, fps = [], [], [], []\n",
    "    \n",
    "    for dev in T_range: \n",
    "        TP_rate, FP_rate, accuracy,_ = get_TP_FP(hidden_activity, indices, tokens, dev)\n",
    "        # print(TP_rate, FP_rate, dev, accuracy)\n",
    "        if accuracy>max_acc:\n",
    "            max_acc = accuracy\n",
    "            best_threshold = dev \n",
    "            neural_chunk_dictionary[word][step]['layer'][layer]['dev_threshold'] = dev\n",
    "        \n",
    "        for lst, value in zip([accs, tps, fps, layers], [accuracy, TP_rate, FP_rate, layer]):\n",
    "            lst.append(value)\n",
    "        if TP_rate > max_tp:max_tp = TP_rate\n",
    "    #print('------------------')\n",
    "    TP_rate, FP_rate, accuracy,_ = get_TP_FP(hidden_activity, indices, tokens, best_threshold)\n",
    "    # print(TP_rate, FP_rate, accuracy, best_threshold)\n",
    "    # print('------------------')\n",
    "\n",
    "    temp = []\n",
    "    for i in range(0, len(tps)):\n",
    "        if tps[i]>=max_tp:temp.append(fps[i])\n",
    "    \n",
    "    fps_sorted, tps_sorted = zip(*sorted(zip(fps, tps)))\n",
    "    fps_sorted = fps_sorted + (1,)\n",
    "    tps_sorted = tps_sorted + (1,)\n",
    "    auc = np.trapezoid(tps_sorted, fps_sorted)\n",
    "    \n",
    "\n",
    "with open(f\"./neural_chunk_dictionary_sae.pkl\", \"wb\") as file:\n",
    "    pickle.dump(neural_chunk_dictionary, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66ee35a9-7e32-4639-a83e-ced390b039ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cheese is one of the most versatile ingredients in the culinary world, and cheese can be used in everything from savory dishes to desserts. Cheese lovers often enjoy pairing cheese with crackers, wine, or fruit, but cheese also shines in baking. Cake, on the other hand, is the quintessential dessert, with cake being a staple at celebrations. Cake comes in many forms, such as chocolate cake, vanilla cake, or even carrot cake. However, when you bring cheese and cake together to create cheesecake, a magical transformation happens. Cheesecake is a dessert like no other, with cheesecake offering the creaminess of cheese and the sweetness of cake in perfect harmony. Cheesecake can be topped with fruits like strawberries or blueberries, or cheesecake can be flavored with chocolate or caramel. Some people prefer classic cheesecake, while others enjoy a more decadent cheesecake loaded with toppings. Regardless of the variation, cheesecake remains one of the most beloved desserts worldwide. The crust of cheesecake, often made from crushed biscuits or graham crackers, complements the smooth filling, making cheesecake irresistible. Cheese plays a central role in cheesecake, while the influence of cake ensures that cheesecake is always a delightful dessert. Whether you love cheese, crave cake, or are obsessed with cheesecake, this dessert proves that the combination of cheese and cake is truly extraordinary. Every bite of cheesecake reminds us that cheese and cake, when united in cheesecake, are a match made in heaven. Cheesecake aficionados often debate whether baked cheesecake or no-bake cheesecake is superior, but all agree that cheesecake is a dessert worth savoring. With so many variations, cheesecake enthusiasts never tire of exploring new ways to enjoy their favorite dessert. Cheese and cake come together seamlessly in cheesecake, showing how cheese and cake can create something greater than their individual parts. Cheesecake is, without a doubt, the ultimate testament to the greatness of cheese and cake in unison.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39512d-a3a7-4bff-8dec-318771c81dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record neural activity of the top 1 neuron in each layer, responding to the tokenized text \n",
    "# then use the activity to classify input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12932bf-8175-4e4a-a003-8563920eda7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['llama3']\n",
    "words = ['cheese', 'cake','cheesecake'] # 'cheese','cake',\n",
    "trainkey = 'prompt_with_cheesecake_train'\n",
    "testkey = 'prompt_with_cheesecake_test'\n",
    "\n",
    "for model_name in model_names:\n",
    "    for word in words:\n",
    "        decode_chunks_all_models(word, trainkey, testkey, prompt_bank,device, tokenizer, model_name=model_name, step = step, n_training = 5, partword = True)     \n",
    "        # input_text = prompt_bank[trainkey]\n",
    "        # tokens = obtain_sentence_wise_token(tokenizer, input_text, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b090c4-53c4-4519-9d54-bcb321badd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the activity of the biggest sae neuron and store them in a file like this \n",
    "hidden_state = np.load(f'./hidden_unit_activity/{trainkey}_concatenated_hidden_state_layer_{layer}_model={model_name}.npy')\n",
    "# after storing them in a separate file, then use the plotting code to process them "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
